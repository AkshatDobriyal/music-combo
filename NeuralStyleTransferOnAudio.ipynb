{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralStyleTransferOnAudio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8qsRQCWf1bB"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "import librosa\n",
        "import soundfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "import pprint\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Input\n",
        "from keras.models import Model\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "2y9Qfs4QgQ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DT5eY5Ugaa9",
        "outputId": "0eb0bced-ab8f-42bd-dc74-17e99a4f54f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 512"
      ],
      "metadata": {
        "id": "6hqeQO1-ggPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wav_to_mel(file_path):\n",
        "  y, sr = librosa.load(file_path)\n",
        "  audio, _ = librosa.effects.trim(y)\n",
        "  n_fft=2048\n",
        "  hop_length=512\n",
        "  n_mels=128\n",
        "  S = librosa.feature.melspectrogram(audio, sr=sr, n_fft=n_fft, \n",
        "                                  hop_length=hop_length, n_mels=n_mels)\n",
        "  im =Image.fromarray(S).convert('F') \n",
        "  im.show()\n",
        "  output_path = file_path.split('.')[0]+'.tiff'\n",
        "  im.save(file_path.split('.')[0]+'.tiff')\n",
        "  return output_path, sr"
      ],
      "metadata": {
        "id": "hdQ_FtlJoO63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mel_to_wav(file_path, sr):\n",
        "  im=Image.open(file_path) \n",
        "  img=np.array(im)\n",
        "  n_fft=2048\n",
        "  hop_length=512\n",
        "  n_mels=128\n",
        "  wav=librosa.feature.inverse.mel_to_audio(img, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "  print(img)\n",
        "  soundfile.write(file_path.split('.')[0]+'_ext.wav',wav,samplerate=sr)"
      ],
      "metadata": {
        "id": "hslpail0pPzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_mel__path, content_sampeling_rate = wav_to_mel(\"/content/drive/MyDrive/ML-Project/input_wav/classical00000.wav\")\n",
        "style_mel_path, style_sampeling_rate = wav_to_mel(\"/content/drive/MyDrive/ML-Project/input_wav/jazz00000.wav\")"
      ],
      "metadata": {
        "id": "ly2svQ2112CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_image = np.array(Image.open(content_mel__path))\n",
        "content_image = np.expand_dims(content_image, axis=-1)\n",
        "input_shape = content_image.shape\n",
        "print(content_image.shape)\n",
        "content_image = tf.constant(np.reshape(content_image , ((1, ) + content_image.shape)))\n",
        "print(content_image.shape)"
      ],
      "metadata": {
        "id": "ayUZLBMJrP4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style_image = np.array(Image.open(style_mel_path))\n",
        "style_image = np.expand_dims(style_image, axis=-1)\n",
        "print(style_image.shape)\n",
        "style_image = tf.constant(np.reshape(style_image, ((1, ) + style_image.shape)))\n",
        "print(style_image.shape)"
      ],
      "metadata": {
        "id": "y_kxP3SVtIX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = input_shape\n",
        "\n",
        "conv_model = Sequential()\n",
        "conv_model.add(Input(shape=input_shape))\n",
        "conv_model.add(Conv1D(256, 4, activation='relu', input_shape=input_shape[1:]))\n",
        "conv_model.add(Conv1D(128, 4, activation='relu', input_shape=input_shape[1:]))\n",
        "\n",
        "conv_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "conv_model.summary()"
      ],
      "metadata": {
        "id": "sUU3uWwKgnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_content_cost(content_output, generated_output):\n",
        "    #Here to calculate content cost we just need the output of final layer of the model.\n",
        "    #The final layer of the model can be considered as an embedding of the input image\n",
        "    a_C = content_output[-1]\n",
        "    a_G = generated_output[-1]\n",
        "    \n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    #Unrolling a_C and a_G for calculating content loss\n",
        "    a_C_unrolled = tf.reshape(tf.transpose(a_C, perm=[0, 3, 1, 2]), shape=[n_C, -1])\n",
        "    a_G_unrolled = tf.reshape(tf.transpose(a_G, perm=[0, 3, 1, 2]), shape=[n_C, -1])\n",
        "    \n",
        "    J_content = (1/(4*n_H*n_W*n_C))*tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled)))\n",
        "    \n",
        "    return J_content"
      ],
      "metadata": {
        "id": "bBIiyxgdjzQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(A):\n",
        "    GA = tf.linalg.matmul(A, tf.transpose(A))\n",
        "    return GA"
      ],
      "metadata": {
        "id": "67Nap6nbk8qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    a_S = tf.reshape(tf.transpose(a_S, perm=[0, 3, 1, 2]), shape=[n_C, -1])\n",
        "    a_G = tf.reshape(tf.transpose(a_G, perm=[0, 3, 1, 2]), shape=[n_C, -1])\n",
        "\n",
        "    GS = gram_matrix(a_S)\n",
        "    GG = gram_matrix(a_G)\n",
        "\n",
        "    J_style_layer = (1. / (4 * (n_C**2) * (n_H * n_W)**2) )*tf.reduce_sum(tf.square(tf.subtract(GS, GG)))\n",
        "        \n",
        "    return J_style_layer"
      ],
      "metadata": {
        "id": "cYxkbqZSk981"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in conv_model.layers:\n",
        "    print(layer.name)"
      ],
      "metadata": {
        "id": "d0QJoqFFlAmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STYLE_LAYERS = [\n",
        "    ('conv1d', 0.5),\n",
        "    ('conv1d_1', 0.5)\n",
        "]"
      ],
      "metadata": {
        "id": "mKlitTPalJAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):\n",
        "    J_style = 0\n",
        "\n",
        "    # Set a_S to be the hidden layer activation from the layer we have selected.\n",
        "    # The last element of the array contains the content layer image, which must not be used.\n",
        "    a_S = style_image_output[:-1]\n",
        "\n",
        "    # Set a_G to be the output of the choosen hidden layers.\n",
        "    # The last element of the list contains the content layer image which must not be used.\n",
        "    a_G = generated_image_output[:-1]\n",
        "    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  \n",
        "        # Compute style_cost for the current layer\n",
        "        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])\n",
        "\n",
        "        # Add weight * J_style_layer of this layer to overall style cost\n",
        "        J_style += weight[1] * J_style_layer\n",
        "\n",
        "    return J_style"
      ],
      "metadata": {
        "id": "-5wNf4E2lXMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function()\n",
        "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
        "    J = alpha * J_content + beta * J_style\n",
        "\n",
        "    return J"
      ],
      "metadata": {
        "id": "9giM2V1rlaoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
        "noise = tf.random.uniform(tf.shape(generated_image), -0.25, 0.25)\n",
        "generated_image = tf.add(generated_image, noise)\n",
        "generated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "print(generated_image.shape)"
      ],
      "metadata": {
        "id": "3kI1NKn9ldFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=conv_model.input,\n",
        "              outputs=[conv_model.get_layer(layer_name).output for layer_name in ['conv1d', 'conv1d_1']])"
      ],
      "metadata": {
        "id": "AxNoRFNxljL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_content = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
        "a_C = model(preprocessed_content) #Getting outputs of the selected layer for content image"
      ],
      "metadata": {
        "id": "pZX_MLXIltoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
        "a_S = model(preprocessed_style) #Getting outputs of the selected layer for content image"
      ],
      "metadata": {
        "id": "YQR8hpttAmLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_content"
      ],
      "metadata": {
        "id": "BBjabPrH_1Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_style"
      ],
      "metadata": {
        "id": "AuawGknACrO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "@tf.function()\n",
        "def train_step(generated_image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        a_G = model(generated_image)\n",
        "        \n",
        "        J_style = compute_style_cost(a_S, a_G)\n",
        "\n",
        "        J_content = compute_content_cost(a_C, a_G)\n",
        "        \n",
        "        J = total_cost(J_content, J_style, alpha=10, beta=40)\n",
        "                \n",
        "    grad = tape.gradient(J, generated_image)\n",
        "\n",
        "    optimizer.apply_gradients([(grad, generated_image)])\n",
        "    generated_image.assign(tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0))\n",
        "    return J"
      ],
      "metadata": {
        "id": "GgitB9EPCvAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor * 255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor) > 3:\n",
        "      assert tensor.shape[0] == 1\n",
        "      tensor = tensor[0]\n",
        "      tensor = tensor[:, :, 0]\n",
        "  return Image.fromarray(tensor).convert('F')"
      ],
      "metadata": {
        "id": "sHhCyZ13CzRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_image = tf.Variable(generated_image)\n",
        "print(generated_image.shape)\n",
        "\n",
        "epochs = 10000\n",
        "for i in range(epochs):\n",
        "  print(f\"Epoch no {i}\")\n",
        "  train_step(generated_image)\n",
        "  if i % 250 == 0:\n",
        "    image = tensor_to_image(generated_image)\n",
        "    imshow(image)\n",
        "    image.save(f\"/content/drive/MyDrive/ML-Project/output_image/image_{i}.tiff\")\n",
        "    plt.show() "
      ],
      "metadata": {
        "id": "w7xlTUUXDAJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_file_path = \"\"\n",
        "mel_to_wav(\"/content/drive/MyDrive/ML-Project/output_image/image_9750.tiff\", content_sampeling_rate)"
      ],
      "metadata": {
        "id": "-Bq4DIL_DDWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evo3yDEIT6Ak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}